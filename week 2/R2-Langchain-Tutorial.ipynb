{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain 是圍繞 LLMs 構建的框架。我們可以將其用於聊天機器人、Question-Answering (QA)、摘要等等。\n",
    "\n",
    "這個函式庫的核心思想是我們可以將不同的元件 “鏈結” 在一起，以創建更多元的 LLMs 應用。 Chain 來自幾個 Module 的多個組件：\n",
    "\n",
    "1. **Prompt templates**：Prompt templates 是不同類型提示的範本。例如「 chatbot 」樣式模板、ELI5 問答等\n",
    "2. **LLMs**：像 GPT-3、Mistral、Llama、Breeze、TAIDE 等大型語言模型\n",
    "3. **Agents**：Agents 使用 LLMs 決定應採取的動作。可以使用網路搜尋(Google Search)或計算器(Python func)之類的工具，並將所有工具包裝成一個邏輯循環的操作。\n",
    "4. **Memory**：短期記憶、長期記憶。\n",
    "\n",
    "我們將從 Prompt templates 和 LLMs 的基礎知識開始。以下教學將提供兩個 LLMs 選項，包含 Hugging Face Hub 或 Hugging Face Pipeline 的模型。\n",
    "\n",
    "- GitHub: https://github.com/langchain-ai/langchain\n",
    "- Docs: https://python.langchain.com/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_huggingface import ChatHuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# chat model 需要使用 hf 的 token\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LLMs\n",
    "透過 Langchain 載入 Huggingface 上的各種大型語言模型，在 Langchain 內模型可以分為\n",
    "\n",
    "1. LLM 模式：給予文字輸入，然後文字輸出\n",
    "\n",
    "2. Chat Models 模式：基於LLM模式的更進階的模式，他的輸入和輸出是格式化的chat messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"MediaTek-Research/Breeze-7B-Instruct-v0_1\"\n",
    "\n",
    "# 量化參數\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True)\n",
    "\n",
    "# llm 初始化\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=MODEL_NAME,\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs=dict(\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=quantization_config),\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.0001,\n",
    "        top_p=0.95,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.15) )\n",
    "\n",
    "# chat model 初始化\n",
    "chat_llm = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "提問: 2022 年全球最賣座的電影是哪一部?\n",
    "\n",
    "Let's think step by step.\n",
    "\n",
    "解答: \"\"\"\n",
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "提問: NBA 2023 年總冠軍球隊是誰?\n",
    "\n",
    "Let's think step by step.\n",
    "\n",
    "解答: \"\"\"\n",
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prompt\n",
    "一個好的 Prompt 通常包含以下四個組成部分：\n",
    "\n",
    "1. **指示**: 告訴模型要做什麼，如何使用提供的信息，如何處理查詢，並建立輸出\n",
    "2. **範例輸入**: 提供範例輸入，以向模型示範預期的內容\n",
    "3. **範例輸出**: 提供對應的範例輸出\n",
    "4. **查詢**: 您希望模型處理的實際輸入\n",
    "\n",
    "以下介紹幾種在 LangChain 上使用 Pormpt 的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化提示詞模板\n",
    "prompt_template = PromptTemplate.from_template(\"告訴我一個笑話\")\n",
    "message = prompt_template.format()\n",
    "\n",
    "# 模型生成\n",
    "print(llm(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化提示詞模板\n",
    "prompt_template = PromptTemplate.from_template(\"告訴我關於一個{content}的{adjective}笑話。\")\n",
    "message = prompt_template.format(adjective=\"悲傷的\", content=\"數據科學家\")\n",
    "\n",
    "# 模型生成\n",
    "print(llm(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一個擁有強大能力的 AI 機器人。你的名字是{name}。\"),\n",
    "        (\"human\", \"你好，你好嗎？\"),\n",
    "        (\"ai\", \"我很好，謝謝！\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"你叫什麼名字？\")\n",
    "print(chat_llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 混合使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"你是一個擁有強大能力的 AI 機器人。\"\n",
    "question_prompt = \"告訴我關於一個{content}的{adjective}笑話。\"\n",
    "\n",
    "full_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(\"你好，你好嗎？\"),\n",
    "    AIMessage(\"我很好，謝謝！\"),\n",
    "    HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=question_prompt,\n",
    "            input_variables=[\"content\", \"adjective\"])\n",
    "    )\n",
    "])\n",
    "full_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LLM Chain\n",
    "對於簡單的任務，使用單一 LLM（大型語言模型）效果很好。然而，對於更複雜的任務，通常需要鍊式多個步驟和/或模型。\n",
    "\n",
    "在LangChain中，可以使用傳統的 LLMChain，較新且建議的方法是 LangChain 表達式語言（LCEL）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"問題: {question}\n",
    "\n",
    "Let's think step by step.\n",
    "\n",
    "答案: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# 使用 LLM Chain 將 Prompt 與 LLM 串接起來\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# 將問題透過參數化的方式帶入\n",
    "question = \"NBA 2023 年總冠軍球隊是誰?\"\n",
    "print(llm_chain.invoke({\"question\": question})[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LCEL（LangChain Expression Language）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要加入 Instruction 參數，才能告訴模型你的對話結束了，因目前使用的模型上不支援 chat 模式\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一位專業的資料科學家和機器學習工程師，能夠提供專業的知識並準確地回答問題。\",),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 使用 LCEL 將 Prompt 與 LLM 等串接起來\n",
    "llm_chain = prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "# 將問題透過參數化的方式帶入\n",
    "print(llm_chain.invoke({\"question\": \"機器學習和深度學習有什麼不同？\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
